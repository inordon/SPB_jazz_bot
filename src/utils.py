import asyncio
import logging
import smtplib
import json
import os
import time
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
from typing import Optional, Dict, List, Any
from datetime import datetime, timedelta
from pathlib import Path

logger = logging.getLogger(__name__)

class EmailSender:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ email —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏"""

    def __init__(self, smtp_server: str, smtp_port: int, email_user: str, email_password: str):
        self.smtp_server = smtp_server
        self.smtp_port = smtp_port
        self.email_user = email_user
        self.email_password = email_password
        self.last_send_time = {}  # –î–ª—è rate limiting
        self.send_count = {"hour": 0, "day": 0, "last_reset": datetime.now()}

    async def send_email(self, to_email: str, subject: str, body: str,
                         html_body: str = None, attachments: List[str] = None,
                         priority: str = "normal") -> bool:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ email —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤–ª–æ–∂–µ–Ω–∏–π –∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ rate limit
            if not self._check_rate_limit(to_email):
                logger.warning(f"Rate limit exceeded for {to_email}")
                return False

            msg = MIMEMultipart('alternative')
            msg['Subject'] = subject
            msg['From'] = self.email_user
            msg['To'] = to_email

            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
            if priority == "high":
                msg['X-Priority'] = '1'
                msg['X-MSMail-Priority'] = 'High'
            elif priority == "low":
                msg['X-Priority'] = '5'
                msg['X-MSMail-Priority'] = 'Low'

            # –¢–µ–∫—Å—Ç–æ–≤–∞—è –≤–µ—Ä—Å–∏—è
            text_part = MIMEText(body, 'plain', 'utf-8')
            msg.attach(text_part)

            # HTML –≤–µ—Ä—Å–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
            if html_body:
                html_part = MIMEText(html_body, 'html', 'utf-8')
                msg.attach(html_part)

            # –í–ª–æ–∂–µ–Ω–∏—è
            if attachments:
                for file_path in attachments:
                    if os.path.exists(file_path):
                        with open(file_path, "rb") as attachment:
                            part = MIMEBase('application', 'octet-stream')
                            part.set_payload(attachment.read())
                            encoders.encode_base64(part)
                            part.add_header(
                                'Content-Disposition',
                                f'attachment; filename= {os.path.basename(file_path)}'
                            )
                            msg.attach(part)

            # –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(None, self._send_smtp, msg, to_email)

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—á–µ—Ç—á–∏–∫–æ–≤
            self._update_counters()
            self.last_send_time[to_email] = datetime.now()

            logger.info(f"Email sent successfully to {to_email}")
            return True

        except Exception as e:
            logger.error(f"Failed to send email to {to_email}: {e}")
            return False

    def _send_smtp(self, msg, to_email: str):
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ SMTP"""
        with smtplib.SMTP(self.smtp_server, self.smtp_port) as server:
            server.starttls()
            server.login(self.email_user, self.email_password)
            server.send_message(msg, to_addresses=[to_email])

    def _check_rate_limit(self, email: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ rate limit –¥–ª—è email"""
        now = datetime.now()

        # –ì–ª–æ–±–∞–ª—å–Ω—ã–π rate limit (100 –ø–∏—Å–µ–º –≤ —á–∞—Å, 500 –≤ –¥–µ–Ω—å)
        if self.send_count["hour"] >= 100 or self.send_count["day"] >= 500:
            return False

        # Rate limit –Ω–∞ email (1 –ø–∏—Å—å–º–æ –≤ 5 –º–∏–Ω—É—Ç)
        if email in self.last_send_time:
            time_diff = (now - self.last_send_time[email]).total_seconds()
            if time_diff < 300:  # 5 –º–∏–Ω—É—Ç
                return False

        return True

    def _update_counters(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—á–µ—Ç—á–∏–∫–æ–≤ –æ—Ç–ø—Ä–∞–≤–∫–∏"""
        now = datetime.now()
        last_reset = self.send_count["last_reset"]

        # –°–±—Ä–æ—Å —á–∞—Å–æ–≤–æ–≥–æ —Å—á–µ—Ç—á–∏–∫–∞
        if (now - last_reset).total_seconds() > 3600:
            self.send_count["hour"] = 0

        # –°–±—Ä–æ—Å –¥–Ω–µ–≤–Ω–æ–≥–æ —Å—á–µ—Ç—á–∏–∫–∞
        if now.date() > last_reset.date():
            self.send_count["day"] = 0
            self.send_count["last_reset"] = now

        self.send_count["hour"] += 1
        self.send_count["day"] += 1

    async def send_support_notification(self, ticket_id: int, user_email: str,
                                        message: str, user_name: str) -> bool:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É"""
        subject = f"–ù–æ–≤–æ–µ –æ–±—Ä–∞—â–µ–Ω–∏–µ #{ticket_id} –æ—Ç {user_name}"

        html_body = f"""
        <h2>–ù–æ–≤–æ–µ –æ–±—Ä–∞—â–µ–Ω–∏–µ –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É</h2>
        <p><strong>ID —Ç–∏–∫–µ—Ç–∞:</strong> #{ticket_id}</p>
        <p><strong>–û—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:</strong> {user_name}</p>
        <p><strong>Email:</strong> {user_email}</p>
        <p><strong>–í—Ä–µ–º—è:</strong> {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}</p>
        
        <h3>–°–æ–æ–±—â–µ–Ω–∏–µ:</h3>
        <div style="border: 1px solid #ccc; padding: 10px; background-color: #f9f9f9;">
            {message.replace('\n', '<br>')}
        </div>
        
        <p><em>–≠—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç —Å–∏—Å—Ç–µ–º—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ñ–µ—Å—Ç–∏–≤–∞–ª—è.</em></p>
        """

        text_body = f"""
–ù–æ–≤–æ–µ –æ–±—Ä–∞—â–µ–Ω–∏–µ –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É

ID —Ç–∏–∫–µ—Ç–∞: #{ticket_id}
–û—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_name}
Email: {user_email}
–í—Ä–µ–º—è: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}

–°–æ–æ–±—â–µ–Ω–∏–µ:
{message}

---
–≠—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç —Å–∏—Å—Ç–µ–º—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ñ–µ—Å—Ç–∏–≤–∞–ª—è.
        """

        from config import config
        if config.SUPPORT_EMAIL:
            return await self.send_email(
                config.SUPPORT_EMAIL,
                subject,
                text_body,
                html_body,
                priority="high"
            )

        return False

class DataBackup:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏"""

    def __init__(self, database):
        self.db = database
        self.backup_path = Path("backups")
        self.backup_path.mkdir(exist_ok=True)

    async def create_backup(self, include_full_history: bool = False) -> dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –ø–æ–ª–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π"""
        try:
            backup_data = {
                "timestamp": datetime.now().isoformat(),
                "version": "2.0",
                "backup_type": "full" if include_full_history else "recent",
                "tables": {}
            }

            async with self.db.get_connection() as conn:
                # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ (–≤—Å–µ—Ö)
                users = await conn.fetch("SELECT * FROM users ORDER BY created_at DESC")
                backup_data["tables"]["users"] = [dict(user) for user in users]

                # –¢–∏–∫–µ—Ç—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏
                if include_full_history:
                    tickets = await conn.fetch("SELECT * FROM support_tickets ORDER BY created_at DESC")
                else:
                    # –¢–æ–ª—å–∫–æ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π
                    cutoff_date = datetime.now() - timedelta(days=30)
                    tickets = await conn.fetch(
                        "SELECT * FROM support_tickets WHERE created_at > $1 ORDER BY created_at DESC",
                        cutoff_date
                    )
                backup_data["tables"]["support_tickets"] = [dict(ticket) for ticket in tickets]

                # –°–æ–æ–±—â–µ–Ω–∏—è —Ç–∏–∫–µ—Ç–æ–≤
                if include_full_history:
                    messages = await conn.fetch("SELECT * FROM ticket_messages ORDER BY created_at DESC")
                else:
                    cutoff_date = datetime.now() - timedelta(days=30)
                    messages = await conn.fetch(
                        "SELECT * FROM ticket_messages WHERE created_at > $1 ORDER BY created_at DESC",
                        cutoff_date
                    )
                backup_data["tables"]["ticket_messages"] = [dict(msg) for msg in messages]

                # –û—Ç–∑—ã–≤—ã (–≤—Å–µ—Ö)
                feedback = await conn.fetch("SELECT * FROM feedback ORDER BY created_at DESC")
                backup_data["tables"]["feedback"] = [dict(fb) for fb in feedback]

                # –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ (–≤—Å–µ—Ö)
                schedule = await conn.fetch("SELECT * FROM schedule ORDER BY day, time")
                backup_data["tables"]["schedule"] = [dict(item) for item in schedule]

                # –õ–æ–∫–∞—Ü–∏–∏ (–≤—Å–µ—Ö)
                locations = await conn.fetch("SELECT * FROM locations ORDER BY name")
                backup_data["tables"]["locations"] = [dict(loc) for loc in locations]

                # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (–≤—Å–µ—Ö)
                activities = await conn.fetch("SELECT * FROM activities ORDER BY name")
                backup_data["tables"]["activities"] = [dict(act) for act in activities]

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000 –∑–∞–ø–∏—Å–µ–π)
                stats = await conn.fetch(
                    "SELECT * FROM usage_stats ORDER BY created_at DESC LIMIT 1000"
                )
                backup_data["tables"]["usage_stats"] = [dict(stat) for stat in stats]

                # Rate limits (—Ç–µ–∫—É—â–∏–µ)
                rate_limits = await conn.fetch("SELECT * FROM user_rate_limits")
                backup_data["tables"]["user_rate_limits"] = [dict(rl) for rl in rate_limits]

                # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ (–∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 90 –¥–Ω–µ–π)
                cutoff_date = datetime.now() - timedelta(days=90)
                metrics = await conn.fetch(
                    "SELECT * FROM support_metrics WHERE date > $1 ORDER BY date DESC",
                    cutoff_date.date()
                )
                backup_data["tables"]["support_metrics"] = [dict(metric) for metric in metrics]

            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            backup_data["metadata"] = {
                "total_users": len(backup_data["tables"]["users"]),
                "total_tickets": len(backup_data["tables"]["support_tickets"]),
                "total_messages": len(backup_data["tables"]["ticket_messages"]),
                "total_feedback": len(backup_data["tables"]["feedback"]),
                "backup_size_mb": self._calculate_backup_size(backup_data)
            }

            logger.info(f"Backup created successfully: {backup_data['metadata']}")
            return backup_data

        except Exception as e:
            logger.error(f"Failed to create backup: {e}")
            raise

    async def save_backup_to_file(self, backup_data: dict, filename: str = None) -> str:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –≤ —Ñ–∞–π–ª"""
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_type = backup_data.get("backup_type", "unknown")
            filename = f"backup_{backup_type}_{timestamp}.json"

        file_path = self.backup_path / filename

        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(backup_data, f, ensure_ascii=False, indent=2, default=str)

            logger.info(f"Backup saved to: {file_path}")
            return str(file_path)

        except Exception as e:
            logger.error(f"Failed to save backup to file: {e}")
            raise

    async def restore_from_backup(self, backup_file: str, tables: List[str] = None) -> bool:
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
        try:
            with open(backup_file, 'r', encoding='utf-8') as f:
                backup_data = json.load(f)

            if not tables:
                tables = backup_data["tables"].keys()

            async with self.db.get_connection() as conn:
                for table_name in tables:
                    if table_name not in backup_data["tables"]:
                        logger.warning(f"Table {table_name} not found in backup")
                        continue

                    # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
                    # –≠—Ç–æ —Å–ª–æ–∂–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è, —Ç—Ä–µ–±—É—é—â–∞—è –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç–∏
                    logger.info(f"Restoring table: {table_name}")
                    # TODO: Implement table-specific restoration logic

            logger.info(f"Backup restored successfully from: {backup_file}")
            return True

        except Exception as e:
            logger.error(f"Failed to restore from backup: {e}")
            return False

    def _calculate_backup_size(self, backup_data: dict) -> float:
        """–†–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –≤ –ú–ë"""
        try:
            backup_json = json.dumps(backup_data, default=str)
            size_bytes = len(backup_json.encode('utf-8'))
            size_mb = size_bytes / (1024 * 1024)
            return round(size_mb, 2)
        except:
            return 0.0

    async def cleanup_old_backups(self, keep_count: int = 10):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π"""
        try:
            backup_files = list(self.backup_path.glob("backup_*.json"))
            backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)

            for backup_file in backup_files[keep_count:]:
                backup_file.unlink()
                logger.info(f"Removed old backup: {backup_file}")

        except Exception as e:
            logger.error(f"Failed to cleanup old backups: {e}")

class HealthChecker:
    """–ö–ª–∞—Å—Å –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –±–æ—Ç–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏"""

    def __init__(self, database, bot):
        self.db = database
        self.bot = bot
        self.last_check = None
        self.is_healthy = True
        self.health_history = []
        self.max_history = 100

    async def health_check(self) -> dict:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã"""
        health_status = {
            "timestamp": datetime.now().isoformat(),
            "bot_status": "unknown",
            "database_status": "unknown",
            "memory_usage": "unknown",
            "response_time": 0,
            "errors": [],
            "warnings": []
        }

        start_time = time.time()

        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–æ—Ç–∞
            bot_info = await self.bot.get_me()
            health_status["bot_status"] = "healthy" if bot_info else "error"
            health_status["bot_info"] = {
                "username": bot_info.username,
                "first_name": bot_info.first_name,
                "can_join_groups": bot_info.can_join_groups,
                "can_read_all_group_messages": bot_info.can_read_all_group_messages
            }
        except Exception as e:
            health_status["bot_status"] = "error"
            health_status["errors"].append(f"Bot error: {str(e)}")

        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ë–î
            async with self.db.get_connection() as conn:
                await conn.fetchval("SELECT 1")

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –ë–î
                db_size = await conn.fetchval("""
                    SELECT pg_size_pretty(pg_database_size(current_database()))
                """)

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
                active_connections = await conn.fetchval("""
                    SELECT count(*) FROM pg_stat_activity 
                    WHERE state = 'active' AND datname = current_database()
                """)

                health_status["database_status"] = "healthy"
                health_status["database_info"] = {
                    "size": db_size,
                    "active_connections": active_connections
                }

        except Exception as e:
            health_status["database_status"] = "error"
            health_status["errors"].append(f"Database error: {str(e)}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
        try:
            import psutil
            process = psutil.Process()
            memory_info = process.memory_info()
            memory_percent = process.memory_percent()

            health_status["memory_usage"] = {
                "rss_mb": round(memory_info.rss / 1024 / 1024, 2),
                "vms_mb": round(memory_info.vms / 1024 / 1024, 2),
                "percent": round(memory_percent, 2)
            }

            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –ø–∞–º—è—Ç–∏
            if memory_percent > 80:
                health_status["warnings"].append(f"High memory usage: {memory_percent:.1f}%")

        except ImportError:
            health_status["memory_usage"] = "psutil not available"
        except Exception as e:
            health_status["warnings"].append(f"Memory check error: {str(e)}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–∫–ª–∏–∫–∞
        end_time = time.time()
        response_time = round((end_time - start_time) * 1000, 2)  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
        health_status["response_time"] = response_time

        if response_time > 5000:  # –±–æ–ª–µ–µ 5 —Å–µ–∫—É–Ω–¥
            health_status["warnings"].append(f"Slow response time: {response_time}ms")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ—á–µ—Ä–µ–¥–µ–π –∏ —Ç–∏–∫–µ—Ç–æ–≤
        try:
            stats = await self._check_support_health()
            health_status["support_health"] = stats

            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –ø–æ –ø–æ–¥–¥–µ—Ä–∂–∫–µ
            if stats["urgent_tickets"] > 10:
                health_status["warnings"].append(f"Many urgent tickets: {stats['urgent_tickets']}")

            if stats["open_tickets"] > 50:
                health_status["warnings"].append(f"Many open tickets: {stats['open_tickets']}")

        except Exception as e:
            health_status["warnings"].append(f"Support health check error: {str(e)}")

        # –û–±—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.last_check = datetime.now()
        self.is_healthy = len(health_status["errors"]) == 0

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.health_history.append({
            "timestamp": health_status["timestamp"],
            "is_healthy": self.is_healthy,
            "response_time": response_time,
            "errors_count": len(health_status["errors"]),
            "warnings_count": len(health_status["warnings"])
        })

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏—Å—Ç–æ—Ä–∏–∏
        if len(self.health_history) > self.max_history:
            self.health_history = self.health_history[-self.max_history:]

        return health_status

    async def _check_support_health(self) -> dict:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏"""
        try:
            async with self.db.get_connection() as conn:
                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∫—Ä—ã—Ç—ã—Ö —Ç–∏–∫–µ—Ç–æ–≤
                open_tickets = await conn.fetchval(
                    "SELECT COUNT(*) FROM support_tickets WHERE is_closed = FALSE"
                )

                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ä–æ—á–Ω—ã—Ö —Ç–∏–∫–µ—Ç–æ–≤ (–±–µ–∑ –æ—Ç–≤–µ—Ç–∞ > 2 —á–∞—Å–æ–≤)
                urgent_tickets = await conn.fetchval("""
                    SELECT COUNT(*) FROM support_tickets 
                    WHERE is_closed = FALSE 
                    AND (last_staff_response_at IS NULL OR last_user_message_at > last_staff_response_at)
                    AND last_user_message_at < NOW() - INTERVAL '2 hours'
                """)

                # –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é
                avg_queue_size = await conn.fetchval("""
                    SELECT AVG(open_count) FROM (
                        SELECT DATE(created_at), COUNT(*) as open_count
                        FROM support_tickets 
                        WHERE created_at > NOW() - INTERVAL '7 days'
                        GROUP BY DATE(created_at)
                    ) as daily_counts
                """)

                return {
                    "open_tickets": open_tickets,
                    "urgent_tickets": urgent_tickets,
                    "avg_queue_size": round(avg_queue_size or 0, 1)
                }

        except Exception as e:
            logger.error(f"Support health check error: {e}")
            return {"error": str(e)}

    def get_health_trends(self, hours: int = 24) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∑–¥–æ—Ä–æ–≤—å—è"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=hours)

            recent_checks = [
                check for check in self.health_history
                if datetime.fromisoformat(check["timestamp"]) > cutoff_time
            ]

            if not recent_checks:
                return {"error": "No recent health checks"}

            # –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            healthy_count = sum(1 for check in recent_checks if check["is_healthy"])
            avg_response_time = sum(check["response_time"] for check in recent_checks) / len(recent_checks)
            total_errors = sum(check["errors_count"] for check in recent_checks)
            total_warnings = sum(check["warnings_count"] for check in recent_checks)

            return {
                "period_hours": hours,
                "total_checks": len(recent_checks),
                "healthy_percentage": round((healthy_count / len(recent_checks)) * 100, 1),
                "avg_response_time": round(avg_response_time, 2),
                "total_errors": total_errors,
                "total_warnings": total_warnings,
                "last_check": recent_checks[-1]["timestamp"] if recent_checks else None
            }

        except Exception as e:
            logger.error(f"Error calculating health trends: {e}")
            return {"error": str(e)}

class SecurityMonitor:
    """–ö–ª–∞—Å—Å –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""

    def __init__(self, database):
        self.db = database
        self.suspicious_activities = []
        self.blocked_users = set()

    async def check_user_activity(self, user_id: int, action: str, details: dict = None) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
            hour_ago = datetime.now() - timedelta(hours=1)

            async with self.db.get_connection() as conn:
                recent_actions = await conn.fetch("""
                    SELECT action, details, created_at FROM usage_stats
                    WHERE user_id = $1 AND created_at > $2
                    ORDER BY created_at DESC
                """, user_id, hour_ago)

            # –ê–Ω–∞–ª–∏–∑ –Ω–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            suspicious_score = 0

            # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏–π –∑–∞ –∫–æ—Ä–æ—Ç–∫–æ–µ –≤—Ä–µ–º—è
            if len(recent_actions) > 100:
                suspicious_score += 50

            # –ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –¥–µ–π—Å—Ç–≤–∏—è
            action_counts = {}
            for row in recent_actions:
                action_counts[row['action']] = action_counts.get(row['action'], 0) + 1

            max_action_count = max(action_counts.values()) if action_counts else 0
            if max_action_count > 50:
                suspicious_score += 30

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ø–∞–º –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö –ø–æ–¥–¥–µ—Ä–∂–∫–∏
            if action == "support_message":
                message_text = details.get("message", "") if details else ""
                if self._is_spam_message(message_text):
                    suspicious_score += 70

            # –ï—Å–ª–∏ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ø–æ—Ä–æ–≥
            if suspicious_score > 70:
                await self._handle_suspicious_user(user_id, suspicious_score, action, details)
                return False

            return True

        except Exception as e:
            logger.error(f"Error checking user activity: {e}")
            return True  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Ä–∞–∑—Ä–µ—à–∞–µ–º –¥–µ–π—Å—Ç–≤–∏–µ

    def _is_spam_message(self, message: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ —Å–ø–∞–º"""
        from config import config

        spam_indicators = [
            len(message) > 2000,  # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            message.count("http") > 3,  # –ú–Ω–æ–≥–æ —Å—Å—ã–ª–æ–∫
            message.count("@") > 5,  # –ú–Ω–æ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
            any(word in message.lower() for word in config.get_security_config()["blacklisted_words"])
        ]

        return sum(spam_indicators) >= 2

    async def _handle_suspicious_user(self, user_id: int, score: int, action: str, details: dict):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—É—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            suspicious_activity = {
                "user_id": user_id,
                "score": score,
                "action": action,
                "details": details,
                "timestamp": datetime.now().isoformat()
            }

            self.suspicious_activities.append(suspicious_activity)

            # –í—Ä–µ–º–µ–Ω–Ω–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–º —Å–∫–æ—Ä–µ
            if score > 90:
                self.blocked_users.add(user_id)

                # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤
                from config import config
                message = f"""
üö® –ü–û–î–û–ó–†–ò–¢–ï–õ–¨–ù–ê–Ø –ê–ö–¢–ò–í–ù–û–°–¢–¨

üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_id}
üìä –°–∫–æ—Ä: {score}/100
üéØ –î–µ–π—Å—Ç–≤–∏–µ: {action}
‚è∞ –í—Ä–µ–º—è: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}

üîí –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω
                """

                # TODO: –û—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞–º

            logger.warning(f"Suspicious activity detected: user {user_id}, score {score}")

        except Exception as e:
            logger.error(f"Error handling suspicious user: {e}")

    def is_user_blocked(self, user_id: int) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"""
        return user_id in self.blocked_users

    def unblock_user(self, user_id: int):
        """–†–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        self.blocked_users.discard(user_id)

class PerformanceMonitor:
    """–ö–ª–∞—Å—Å –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""

    def __init__(self):
        self.metrics = {
            "request_times": [],
            "memory_usage": [],
            "cpu_usage": [],
            "db_query_times": []
        }
        self.start_time = time.time()

    def record_request_time(self, duration: float):
        """–ó–∞–ø–∏—Å—å –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞"""
        self.metrics["request_times"].append({
            "duration": duration,
            "timestamp": time.time()
        })

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
        if len(self.metrics["request_times"]) > 1000:
            self.metrics["request_times"] = self.metrics["request_times"][-1000:]

    def record_db_query_time(self, duration: float):
        """–ó–∞–ø–∏—Å—å –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è SQL –∑–∞–ø—Ä–æ—Å–∞"""
        self.metrics["db_query_times"].append({
            "duration": duration,
            "timestamp": time.time()
        })

        if len(self.metrics["db_query_times"]) > 500:
            self.metrics["db_query_times"] = self.metrics["db_query_times"][-500:]

    def get_performance_stats(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            current_time = time.time()
            uptime = current_time - self.start_time

            stats = {
                "uptime_seconds": round(uptime, 2),
                "uptime_formatted": str(timedelta(seconds=int(uptime)))
            }

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
            if self.metrics["request_times"]:
                recent_requests = [
                    r for r in self.metrics["request_times"]
                    if current_time - r["timestamp"] < 3600  # –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
                ]

                if recent_requests:
                    durations = [r["duration"] for r in recent_requests]
                    stats["requests"] = {
                        "count_last_hour": len(recent_requests),
                        "avg_duration_ms": round(sum(durations) / len(durations) * 1000, 2),
                        "max_duration_ms": round(max(durations) * 1000, 2),
                        "min_duration_ms": round(min(durations) * 1000, 2)
                    }

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ë–î –∑–∞–ø—Ä–æ—Å–æ–≤
            if self.metrics["db_query_times"]:
                recent_queries = [
                    q for q in self.metrics["db_query_times"]
                    if current_time - q["timestamp"] < 3600
                ]

                if recent_queries:
                    durations = [q["duration"] for q in recent_queries]
                    stats["database"] = {
                        "queries_last_hour": len(recent_queries),
                        "avg_query_time_ms": round(sum(durations) / len(durations) * 1000, 2),
                        "max_query_time_ms": round(max(durations) * 1000, 2)
                    }

            # –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            try:
                import psutil
                process = psutil.Process()

                stats["system"] = {
                    "memory_percent": round(process.memory_percent(), 2),
                    "cpu_percent": round(process.cpu_percent(), 2),
                    "threads": process.num_threads(),
                    "open_files": len(process.open_files())
                }
            except ImportError:
                stats["system"] = "psutil not available"

            return stats

        except Exception as e:
            logger.error(f"Error getting performance stats: {e}")
            return {"error": str(e)}